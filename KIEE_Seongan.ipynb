{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yy\n",
      "      0\n",
      "0     9\n",
      "1    33\n",
      "2     0\n",
      "3     6\n",
      "4    26\n",
      "..   ..\n",
      "796  35\n",
      "797  27\n",
      "798  28\n",
      "799  11\n",
      "800   4\n",
      "\n",
      "[801 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train data\n",
    "data=pd.read_excel('C:/Users/jhr96/Desktop/PYTHON/excel/fault_feature_800_new_s_train.xls') # b,c가 정상데이터로 인식 \n",
    "\n",
    "X=data.drop(['target','type','m'],axis=1)\n",
    "y=data.filter(['target'])\n",
    "z=data.filter(['type'])\n",
    "\n",
    "#형래 없고 명찬 있음\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tn, X_te, y_tn, y_te, z_tn, z_te=train_test_split(X,y,z,test_size=0.1,shuffle=True, random_state=1)\n",
    "'''\n",
    "\n",
    "X_ab=data.filter(['VA_am','VA_aph','IA_am','IA_aph','VB_am','VB_aph','IB_am','IB_aph','VA_bm','VA_bph','IA_bm','IA_bph','VB_bm','VB_bph','IB_bm','IB_bph','VC_am','VC_aph','IC_am','IC_aph','VD_am','VD_aph','ID_am','ID_aph','VC_bm','VC_bph','IC_bm','IC_bph','VD_bm','VD_bph','ID_bm','ID_bph'])\n",
    "\n",
    "X_bc=data.filter(['VA_bm','VA_bph','IA_bm','IA_bph','VB_bm','VB_bph','IB_bm','IB_bph','VA_cm','VA_cph','IA_cm','IA_cph','VB_cm','VB_cph','IB_cm','IB_cph','VC_bm','VC_bph','IC_bm','IC_bph','VD_bm','VD_bph','ID_bm','ID_bph','VC_cm','VC_cph','IC_cm','IC_cph','VD_cm','VD_cph','ID_cm','ID_cph'])\n",
    "\n",
    "X_ca=data.filter(['VA_cm','VA_cph','IA_cm','IA_cph','VB_cm','VB_cph','IB_cm','IB_cph','VA_am','VA_aph','IA_am','IA_aph','VB_am','VB_aph','IB_am','IB_aph','VC_cm','VC_cph','IC_cm','IC_cph','VD_cm','VD_cph','ID_cm','ID_cph','VC_am','VC_aph','IC_am','IC_aph','VD_am','VD_aph','ID_am','ID_aph'])\n",
    "\n",
    "\n",
    "row=y.shape[0]\n",
    "yy=y.to_numpy()\n",
    "z=z.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# one-hot     \n",
    "for i in range(0,row-1):\n",
    "    if z[i]==4: \n",
    "        yy[i]=yy[i]-1\n",
    "    elif z[i]==5: \n",
    "        yy[i]=yy[i]+11\n",
    "    else: \n",
    "        yy[i]=yy[i]+23\n",
    "\n",
    "    ''' 정상 데이터??\n",
    "    else:         # 정상데이터 있을 시에 \n",
    "        yy[i]=0\n",
    "    '''\n",
    "\n",
    "yy=pd.DataFrame(yy)\n",
    "z_1=pd.DataFrame(z)\n",
    "\n",
    "print('yy')\n",
    "print(yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#test data\n",
    "data_te=pd.read_excel('C:/Users/jhr96/Desktop/PYTHON/excel/fault_feature_200_new_s_test.xls')\n",
    "\n",
    "X_ab_te=data.filter(['VA_am','VA_aph','IA_am','IA_aph','VB_am','VB_aph','IB_am','IB_aph','VA_bm','VA_bph','IA_bm','IA_bph','VB_bm','VB_bph','IB_bm','IB_bph','VC_am','VC_aph','IC_am','IC_aph','VD_am','VD_aph','ID_am','ID_aph','VC_bm','VC_bph','IC_bm','IC_bph','VD_bm','VD_bph','ID_bm','ID_bph'])\n",
    "\n",
    "X_bc_te=data.filter(['VA_bm','VA_bph','IA_bm','IA_bph','VB_bm','VB_bph','IB_bm','IB_bph','VA_cm','VA_cph','IA_cm','IA_cph','VB_cm','VB_cph','IB_cm','IB_cph','VC_bm','VC_bph','IC_bm','IC_bph','VD_bm','VD_bph','ID_bm','ID_bph','VC_cm','VC_cph','IC_cm','IC_cph','VD_cm','VD_cph','ID_cm','ID_cph'])\n",
    "\n",
    "X_ca_te=data.filter(['VA_cm','VA_cph','IA_cm','IA_cph','VB_cm','VB_cph','IB_cm','IB_cph','VA_am','VA_aph','IA_am','IA_aph','VB_am','VB_aph','IB_am','IB_aph','VC_cm','VC_cph','IC_cm','IC_cph','VD_cm','VD_cph','ID_cm','ID_cph','VC_am','VC_aph','IC_am','IC_aph','VD_am','VD_aph','ID_am','ID_aph'])\n",
    "\n",
    "### 형래 있고 명찬 없음 ######\n",
    "'''\n",
    "y_te=data.filter(['target'])\n",
    "z_te=data.filter(['type'])\n",
    "'''\n",
    "\n",
    "row_te=y_te.shape[0]\n",
    "yy_te=y_te.to_numpy()\n",
    "z_te=z_te.to_numpy()\n",
    "\n",
    "for i in range(0,row_te-1):\n",
    "    if z_te[i]==4:\n",
    "        yy_te[i]=yy_te[i]-1\n",
    "    elif z_te[i]==5:\n",
    "        yy_te[i]=yy_te[i]+11\n",
    "    else:\n",
    "        yy_te[i]=yy_te[i]+23\n",
    "\n",
    "    ''' 정상 데이터??\n",
    "    else:         # 정상데이터 있을 시에 \n",
    "        yy[i]=0\n",
    "    '''\n",
    "\n",
    "yy_te=pd.DataFrame(yy_te)\n",
    "\n",
    "\n",
    "#tn_lda\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda=LinearDiscriminantAnalysis(n_components=3)\n",
    "lda1 = lda.fit(X_ab,y)\n",
    "lda2 = lda.fit(X_bc,y)\n",
    "lda3 = lda.fit(X_ca,y)\n",
    "\n",
    "\n",
    "Xab_lda=lda.transform(X_ab)\n",
    "Xbc_lda=lda.transform(X_bc)\n",
    "Xca_lda=lda.transform(X_ca)\n",
    "\n",
    "\n",
    "print(Xab_lda.shape)\n",
    "print(Xbc_lda.shape)\n",
    "print(Xca_lda.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(lda.explained_variance_ratio_)\n",
    "\n",
    "Xab_lda_df = pd.DataFrame(Xab_lda)\n",
    "Xbc_lda_df = pd.DataFrame(Xbc_lda)\n",
    "Xca_lda_df = pd.DataFrame(Xca_lda)\n",
    "\n",
    "X=pd.concat([Xab_lda_df,Xbc_lda_df,Xca_lda_df],axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "### 형래 있고 명찬 없음 ####\n",
    "#LDA_te\n",
    "#Xab_lda_te = lda1.fit(X_ab_te,y)\n",
    "#lda.fit(X_b_te,y)\n",
    "#lda.fit(X_c_te,y)\n",
    "\n",
    "Xab_lda_te=lda.transform(X_ab_te)\n",
    "Xbc_lda_te=lda.transform(X_ab_te)\n",
    "Xca_lda_te=lda.transform(X_ca_te)\n",
    "\n",
    "\n",
    "print(Xab_lda_te.shape)\n",
    "print(Xbc_lda_te.shape)\n",
    "print(Xca_lda_te.shape)\n",
    "\n",
    "Xab_lda_te_df = pd.DataFrame(Xab_lda_te)\n",
    "Xbc_lda_te_df = pd.DataFrame(Xbc_lda_te)\n",
    "Xca_lda_te_df = pd.DataFrame(Xca_lda_te)\n",
    "\n",
    "X_te=pd.concat([Xab_lda_te_df,Xbc_lda_te_df,Xca_lda_te_df],axis=1)\n",
    "print(X_te.shape)\n",
    "\n",
    "\n",
    "#ANN\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "keras.utils.set_random_seed(10)\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "yyy=to_categorical(yy)\n",
    "yyy_te=to_categorical(yy_te)\n",
    "\n",
    "\n",
    "\n",
    "#'leaky_relu' 'relu' 'elu'\n",
    "# https://yeomko.tistory.com/39 active funtion \n",
    "\n",
    "# Adding the input layer and first hidden layer / Dense 노드의 수 \n",
    "# layer 값이 너무 많아도 gradient vanish를 유발할 수 있어서 조심 / input_dim 9개의 input /\n",
    "classifier.add(Dense(32, kernel_initializer='he_normal', activation = 'leaky_relu', input_dim = 3))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(32, kernel_initializer='he_normal', activation = 'leaky_relu'))\n",
    "# Adding the third hidden layer\n",
    "# classifier.add(Dense(20, kernel_initializer='he_normal', activation = 'leaky_relu'))\n",
    "\n",
    "# Adding the output layer Dense 최종 아웃풋 층을 지정  18개(고장 위치 a,b,c) 값이 나와야함\n",
    "classifier.add(Dense(13, kernel_initializer='he_normal', activation = 'softmax'))\n",
    "classifier.summary()\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting the ANN to the Training set\n",
    "# yy 클래스이름 \n",
    "results=classifier.fit(X, yyy, batch_size = 10, epochs = 600, validation_split = 0.2)\n",
    "\n",
    "\n",
    "for i in range(600):\n",
    "\n",
    "    if results.history['val_accuracy'][i] > results.history['val_accuracy'][i-1]:\n",
    "        from keras.models import load_model\n",
    "        classifier.save('C:/Users/jhr96/Desktop/PYTHON/excel/HR')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(max(results.history['accuracy']))\n",
    "print(max(results.history['val_accuracy']))\n",
    "plt.plot(results.history['accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "####\n",
    "loss_and_metrics = classifier.evaluate(X_te, yyy_te, batch_size=1)\n",
    "where = classifier.predict(X_te,batch_size=1)\n",
    "\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))\n",
    "print(str(where))\n",
    "#####\n",
    "\n",
    "#from keras.models import load_model\n",
    "#model = load_model(\"chan.h5\")\n",
    "\n",
    "#model.evaluate(X_te,yyy_te, batch_size=1)\n",
    "#model.predict(X_te,batch_size=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e65c19e6a3be327988580be0bbb77d33cd3a3bc7b9bdb0b817004f6e1307db33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
